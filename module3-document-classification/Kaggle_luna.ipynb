{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in /anaconda3/envs/NLP/lib/python3.7/site-packages (0.90)\n",
      "Requirement already satisfied: numpy in /anaconda3/envs/NLP/lib/python3.7/site-packages (from xgboost) (1.17.3)\n",
      "Requirement already satisfied: scipy in /anaconda3/envs/NLP/lib/python3.7/site-packages (from xgboost) (1.3.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "#doing the same than this web site https://www.kaggle.com/paul92s/linear-svc-classifier\n",
    "from sklearn.feature_extraction.stop_words import ENGLISH_STOP_WORDS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Classifier imports\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB, BernoulliNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "\n",
    "#from bs4 import BeautifulSoup as soup\n",
    "\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# # Performance metric\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "from spacy.lang.en import English\n",
    "import spacy\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = English()\n",
    "nlp = spacy.load('en_core_web_lg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('./data/train.csv')\n",
    "test = pd.read_csv('./data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>description</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>A marriage of 13 and 18 year old bourbons. A m...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>There have been some legendary Bowmores from t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>This bottling celebrates master distiller Park...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>What impresses me most is how this whisky evol...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>A caramel-laden fruit bouquet, followed by une...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>12</td>\n",
       "      <td>Distilled at the now legendary Stitzel-Weller ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>14</td>\n",
       "      <td>No age statement, but distilled in 1998. A bea...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>15</td>\n",
       "      <td>Monarch, the 75th anniversary limited edition ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>17</td>\n",
       "      <td>The complete package: uncut, unfiltered, full-...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>21</td>\n",
       "      <td>A marriage of four different bourbons, ranging...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>22</td>\n",
       "      <td>Another excellent Stagg, and considering its a...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>23</td>\n",
       "      <td>Sometime recently, the source of this whiskey ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>25</td>\n",
       "      <td>From one barrel, and only sold in one location...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>27</td>\n",
       "      <td>Definitely showing its age, but not in a bad w...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>28</td>\n",
       "      <td>Unlike the standard “small batch” releases, th...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>29</td>\n",
       "      <td>Very similar to last year’s release. (A good t...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>30</td>\n",
       "      <td>Perhaps the finest Canadian whisky I have ever...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>33</td>\n",
       "      <td>This whiskey has improved greatly over the pas...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>34</td>\n",
       "      <td>Very well-balanced and mellow on the nose and ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>35</td>\n",
       "      <td>It’s great that Glenlivet releases whiskies un...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id                                        description  category\n",
       "0    1  A marriage of 13 and 18 year old bourbons. A m...         2\n",
       "1    2  There have been some legendary Bowmores from t...         1\n",
       "2    3  This bottling celebrates master distiller Park...         2\n",
       "3    4  What impresses me most is how this whisky evol...         1\n",
       "4    9  A caramel-laden fruit bouquet, followed by une...         2\n",
       "5   12  Distilled at the now legendary Stitzel-Weller ...         2\n",
       "6   14  No age statement, but distilled in 1998. A bea...         2\n",
       "7   15  Monarch, the 75th anniversary limited edition ...         4\n",
       "8   17  The complete package: uncut, unfiltered, full-...         2\n",
       "9   21  A marriage of four different bourbons, ranging...         2\n",
       "10  22  Another excellent Stagg, and considering its a...         2\n",
       "11  23  Sometime recently, the source of this whiskey ...         2\n",
       "12  25  From one barrel, and only sold in one location...         2\n",
       "13  27  Definitely showing its age, but not in a bad w...         1\n",
       "14  28  Unlike the standard “small batch” releases, th...         2\n",
       "15  29  Very similar to last year’s release. (A good t...         2\n",
       "16  30  Perhaps the finest Canadian whisky I have ever...         4\n",
       "17  33  This whiskey has improved greatly over the pas...         2\n",
       "18  34  Very well-balanced and mellow on the nose and ...         2\n",
       "19  35  It’s great that Glenlivet releases whiskies un...         1"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>955</td>\n",
       "      <td>Think carnival aromas—the good ones, anyway—me...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3532</td>\n",
       "      <td>A blend of three bourbons, between 6 and 12 ye...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1390</td>\n",
       "      <td>The nose is focused on cereal, hints of fresh ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1024</td>\n",
       "      <td>Swiss-based Chapter 7 released this 19 year ol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1902</td>\n",
       "      <td>Valkyrie replaces the current Dark Origins exp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1156</td>\n",
       "      <td>The oldest of Bablair’s current core bottlings...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2205</td>\n",
       "      <td>A sherry butt this time, which has allowed the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>885</td>\n",
       "      <td>This is one of a trio from Chivas Bros., who e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1116</td>\n",
       "      <td>Toasted oak, coffee, cola, molasses, and campf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3739</td>\n",
       "      <td>One of a trio from Chivas Bros., who every yea...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id                                        description\n",
       "0   955  Think carnival aromas—the good ones, anyway—me...\n",
       "1  3532  A blend of three bourbons, between 6 and 12 ye...\n",
       "2  1390  The nose is focused on cereal, hints of fresh ...\n",
       "3  1024  Swiss-based Chapter 7 released this 19 year ol...\n",
       "4  1902  Valkyrie replaces the current Dark Origins exp...\n",
       "5  1156  The oldest of Bablair’s current core bottlings...\n",
       "6  2205  A sherry butt this time, which has allowed the...\n",
       "7   885  This is one of a trio from Chivas Bros., who e...\n",
       "8  1116  Toasted oak, coffee, cola, molasses, and campf...\n",
       "9  3739  One of a trio from Chivas Bros., who every yea..."
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                                                          4075\n",
       "description    A generally sweet palate (a bit too sweet, act...\n",
       "Name: 243, dtype: object"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.iloc[243]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cleaning description\n",
    "#change capitalize to lower\n",
    "#train['description'] = train['description'].apply(lambda x: x.lower())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def tokenize(doc):\n",
    "    tokens = parser(doc)\n",
    "    lemmas = []\n",
    "    for tok in tokens:\n",
    "        lemmas.append(tok.lemma_.lower().strip() if tok.lemma_ != \"-PRON-\" else tok.lower_)\n",
    "    tokens = lemmas\n",
    "    \n",
    "    # Remove all the Stop Words\n",
    "    tokens = [tok for tok in tokens if tok not in ENGLISH_STOP_WORDS]\n",
    "\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       A marriage of 13 and 18 year old bourbons. A m...\n",
       "1       There have been some legendary Bowmores from t...\n",
       "2       This bottling celebrates master distiller Park...\n",
       "3       What impresses me most is how this whisky evol...\n",
       "4       A caramel-laden fruit bouquet, followed by une...\n",
       "5       Distilled at the now legendary Stitzel-Weller ...\n",
       "6       No age statement, but distilled in 1998. A bea...\n",
       "7       Monarch, the 75th anniversary limited edition ...\n",
       "8       The complete package: uncut, unfiltered, full-...\n",
       "9       A marriage of four different bourbons, ranging...\n",
       "10      Another excellent Stagg, and considering its a...\n",
       "11      Sometime recently, the source of this whiskey ...\n",
       "12      From one barrel, and only sold in one location...\n",
       "13      Definitely showing its age, but not in a bad w...\n",
       "14      Unlike the standard “small batch” releases, th...\n",
       "15      Very similar to last year’s release. (A good t...\n",
       "16      Perhaps the finest Canadian whisky I have ever...\n",
       "17      This whiskey has improved greatly over the pas...\n",
       "18      Very well-balanced and mellow on the nose and ...\n",
       "19      It’s great that Glenlivet releases whiskies un...\n",
       "20      Powerful, muscular, well-textured, and invigor...\n",
       "21      The Dalmore is one of a handful of whiskies th...\n",
       "22      A crisp, robust, very dynamic bourbon. Amber-o...\n",
       "23      My review of this whiskey a few years back ind...\n",
       "24      A wheated bourbon from the old Stitzel-Weller ...\n",
       "25      Deep gold color. Surprisingly lively on the no...\n",
       "26      This expression was matured in a European oak ...\n",
       "27      This is a work of art. It begins by revealing ...\n",
       "28      Oh, the glory of used cooperage. Woody notes b...\n",
       "29      This 100% rye-grain whisky is distilled in Alb...\n",
       "                              ...                        \n",
       "2556    One of the Barton whiskies acquired by Sazerac...\n",
       "2557    The loyalty to Canadian Leaf shown by some rye...\n",
       "2558    Its age certainly shows, with a good dose of l...\n",
       "2559    Huge oak impact for such a young whisky. Fresh...\n",
       "2560    Deep, thick nose, with sappy oak, dried citrus...\n",
       "2561    Showing its youth through an obvious green cha...\n",
       "2562    The nose on this whiskey is like smelling a we...\n",
       "2563    A tad thin for sipping, Five Star is a quintes...\n",
       "2564    This Lowland distillery only operated from 195...\n",
       "2565    \" Straight from them there oak cask barrels to...\n",
       "2566    There are flavored—cinnamon and coconut—versio...\n",
       "2567    Maple syrup and gelatin capsules in a veterina...\n",
       "2568    Aged for “at least” one month, this bourbon is...\n",
       "2569    Many moonshine products are centered around co...\n",
       "2570    Perhaps my least favorite of all the Experimen...\n",
       "2571    Origins is Benromach’s new program to highligh...\n",
       "2572    Quite pale in color. Very youthful and naked, ...\n",
       "2573    Youthful, and somewhat brooding for a Tomintou...\n",
       "2574    The nose starts with sweet corn, cornmeal, yea...\n",
       "2575    A big bourbon in many respects, but this is on...\n",
       "2576    Aged in a sherry cask, which adds sweet notes ...\n",
       "2577    Traces of burnt caramel add interest to an oth...\n",
       "2578    Clear, slight golden hue; as expected from a 7...\n",
       "2579    It does say “whisky” on the label...followed b...\n",
       "2580    The sherry is very dominant and cloying, which...\n",
       "2581    Earthy, fleshy notes with brooding grape notes...\n",
       "2582    With its overt floral perfume notes and the sc...\n",
       "2583    An unaged whiskey from Carroll County, Iowa, w...\n",
       "2584    Fiery peat kiln smoke, tar, and ripe barley on...\n",
       "2585    Although it’s not on the label, Cavalry uses t...\n",
       "Name: description, Length: 2586, dtype: object"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['description']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data: (2068, 3)\n",
      "Validation Data: (518, 3)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train, val = train_test_split(train, test_size=0.2, random_state=42)\n",
    "print('Training Data:', train.shape)\n",
    "print('Validation Data:', val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split in X, Y\n",
    "x_train = train['description']\n",
    "y_train = train['category']\n",
    "x_val = val['description']\n",
    "y_val = val['category']\n",
    "x_test = test['description']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect_RFC = TfidfVectorizer(tokenizer=tokenize, ngram_range=(1,2), min_df=5, max_df=0.5)\n",
    "clf_RFC = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('vect', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.float64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=0.5, max_features=None, min_df=5,\n",
       "        ngram_range=(1, 2), norm='l2', preprocessor=None, smooth_idf=True,\n",
       "...obs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False))])"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_RFC = Pipeline([\n",
    "                 ('vect', vect_RFC), \n",
    "                 ('clf', clf_RFC)\n",
    "                ])\n",
    "\n",
    "pipe_RFC.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8436293436293436\n"
     ]
    }
   ],
   "source": [
    "prediction_RFC = pipe_RFC.predict(x_val)\n",
    "print(\"Accuracy:\", accuracy_score(y_val, prediction_RFC))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect_LR = TfidfVectorizer(tokenizer=tokenize, ngram_range=(1,2), min_df=5, max_df=0.5)\n",
    "clf_LR = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('vect', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.float64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=0.5, max_features=None, min_df=5,\n",
       "        ngram_range=(1, 2), norm='l2', preprocessor=None, smooth_idf=True,\n",
       "...obs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False))])"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_LR = Pipeline([\n",
    "                 ('vect', vect_LR), \n",
    "                 ('clf', clf_LR )\n",
    "                ])\n",
    "\n",
    "pipe_LR.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8223938223938224\n"
     ]
    }
   ],
   "source": [
    "prediction_LR = pipe_LR.predict(x_val)\n",
    "print(\"Accuracy:\", accuracy_score(y_val, prediction_LR))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect_XG = TfidfVectorizer(tokenizer=tokenize, ngram_range=(1,2), min_df=5, max_df=0.5)\n",
    "clf_XG = XGBClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('vect', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.float64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=0.5, max_features=None, min_df=5,\n",
       "        ngram_range=(1, 2), norm='l2', preprocessor=None, smooth_idf=True,\n",
       "...\n",
       "       reg_lambda=1, scale_pos_weight=1, seed=None, silent=None,\n",
       "       subsample=1, verbosity=1))])"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_XG = Pipeline([\n",
    "                 ('vect', vect_XG), \n",
    "                 ('clf', clf_XG )\n",
    "                ])\n",
    "\n",
    "pipe_XG.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8957528957528957\n"
     ]
    }
   ],
   "source": [
    "prediction_XG = pipe_XG.predict(x_val)\n",
    "print(\"Accuracy:\", accuracy_score(y_val, prediction_XG))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect_SVC = TfidfVectorizer(tokenizer=tokenize, ngram_range=(1,2), min_df=5, max_df=0.5)\n",
    "clf_SVC = SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('vect', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.float64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=0.5, max_features=None, min_df=5,\n",
       "        ngram_range=(1, 2), norm='l2', preprocessor=None, smooth_idf=True,\n",
       "...f', max_iter=-1, probability=False, random_state=None,\n",
       "  shrinking=True, tol=0.001, verbose=False))])"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_SVC = Pipeline([\n",
    "                 ('vect', vect_SVC), \n",
    "                 ('clf', clf_SVC )\n",
    "                ])\n",
    "\n",
    "pipe_SVC.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6274131274131274\n"
     ]
    }
   ],
   "source": [
    "prediction_SVC = pipe_SVC.predict(x_val)\n",
    "print(\"Accuracy:\", accuracy_score(y_val, prediction_SVC))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect_KN = TfidfVectorizer(tokenizer=tokenize, ngram_range=(1,2), min_df=5, max_df=0.5)\n",
    "clf_KN = KNeighborsClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('vect', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.float64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=0.5, max_features=None, min_df=5,\n",
       "        ngram_range=(1, 2), norm='l2', preprocessor=None, smooth_idf=True,\n",
       "...ki',\n",
       "           metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
       "           weights='uniform'))])"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_KN = Pipeline([\n",
    "                 ('vect', vect_KN), \n",
    "                 ('clf', clf_KN )\n",
    "                ])\n",
    "\n",
    "pipe_KN.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8861003861003861\n"
     ]
    }
   ],
   "source": [
    "prediction_KN = pipe_KN.predict(x_val)\n",
    "print(\"Accuracy:\", accuracy_score(y_val, prediction_KN))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GaussianNB NOT useful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect_GAUSS = TfidfVectorizer(tokenizer=tokenize, ngram_range=(1,2), min_df=5, max_df=0.5)\n",
    "clf_GAUSS = GaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "A sparse matrix was passed, but dense data is required. Use X.toarray() to convert to a dense numpy array.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-178-b9f60288565e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m                 ])\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mpipe_GAUSS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    265\u001b[0m         \u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfit_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 267\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    268\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/sklearn/naive_bayes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    188\u001b[0m         \u001b[0mself\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \"\"\"\n\u001b[0;32m--> 190\u001b[0;31m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    191\u001b[0m         return self._partial_fit(X, y, np.unique(y), _refit=True,\n\u001b[1;32m    192\u001b[0m                                  sample_weight=sample_weight)\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    754\u001b[0m                     \u001b[0mensure_min_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mensure_min_features\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    755\u001b[0m                     \u001b[0mwarn_on_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwarn_on_dtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 756\u001b[0;31m                     estimator=estimator)\n\u001b[0m\u001b[1;32m    757\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    758\u001b[0m         y = check_array(y, 'csr', force_all_finite=True, ensure_2d=False,\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    515\u001b[0m                                       \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m                                       \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_all_finite\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 517\u001b[0;31m                                       accept_large_sparse=accept_large_sparse)\n\u001b[0m\u001b[1;32m    518\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m         \u001b[0;31m# If np.array(..) gives ComplexWarning, then we convert the warning\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_ensure_sparse_format\u001b[0;34m(spmatrix, accept_sparse, dtype, copy, force_all_finite, accept_large_sparse)\u001b[0m\n\u001b[1;32m    316\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0maccept_sparse\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 318\u001b[0;31m         raise TypeError('A sparse matrix was passed, but dense '\n\u001b[0m\u001b[1;32m    319\u001b[0m                         \u001b[0;34m'data is required. Use X.toarray() to '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m                         'convert to a dense numpy array.')\n",
      "\u001b[0;31mTypeError\u001b[0m: A sparse matrix was passed, but dense data is required. Use X.toarray() to convert to a dense numpy array."
     ]
    }
   ],
   "source": [
    "pipe_GAUSS = Pipeline([\n",
    "                 ('vect', vect_GAUSS), \n",
    "                 ('clf', clf_GAUSS )\n",
    "                ])\n",
    "\n",
    "pipe_GAUSS.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_GAUSS = pipe_GAUSS.predict(x_val)\n",
    "print(\"Accuracy:\", accuracy_score(y_val, prediction_GAUSS))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect_MB = TfidfVectorizer(tokenizer=tokenize, ngram_range=(1,2), min_df=5, max_df=0.5)\n",
    "clf_MB = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('vect', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.float64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=0.5, max_features=None, min_df=5,\n",
       "        ngram_range=(1, 2), norm='l2', preprocessor=None, smooth_idf=True,\n",
       "...rue,\n",
       "        vocabulary=None)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_MB = Pipeline([\n",
    "                 ('vect', vect_MB), \n",
    "                 ('clf', clf_MB )\n",
    "                ])\n",
    "\n",
    "pipe_MB.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8301158301158301\n"
     ]
    }
   ],
   "source": [
    "prediction_MB = pipe_MB.predict(x_val)\n",
    "print(\"Accuracy:\", accuracy_score(y_val, prediction_MB))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BernoulliNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect_BNB = TfidfVectorizer(tokenizer=tokenize, ngram_range=(1,2), min_df=5, max_df=0.5)\n",
    "clf_BNB = BernoulliNB()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('vect', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.float64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=0.5, max_features=None, min_df=5,\n",
       "        ngram_range=(1, 2), norm='l2', preprocessor=None, smooth_idf=True,\n",
       "... vocabulary=None)), ('clf', BernoulliNB(alpha=1.0, binarize=0.0, class_prior=None, fit_prior=True))])"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_BNB = Pipeline([\n",
    "                 ('vect', vect_BNB), \n",
    "                 ('clf', clf_BNB )\n",
    "                ])\n",
    "\n",
    "pipe_BNB.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9285714285714286\n"
     ]
    }
   ],
   "source": [
    "prediction_BNB = pipe_BNB.predict(x_val)\n",
    "print(\"Accuracy:\", accuracy_score(y_val, prediction_BNB))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "svd = TruncatedSVD(algorithm='randomized', n_iter=150, random_state=42)\n",
    "vect2 = TfidfVectorizer(stop_words='english')\n",
    "pipe_lsi = Pipeline([('vect', vect2), ('svd', svd)])\n",
    "clf = SGDClassifier(n_iter=1500, random_state=42)\n",
    "\n",
    "pipe_SGDClassifier = Pipeline([('lsi', pipe_lsi), ('clf', clf)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:  1.1min finished\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:152: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('lsi', Pipeline(memory=None,\n",
       "     steps=[('vect', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.float64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), norm=...dom_state=42, shuffle=True, tol=None,\n",
       "       validation_fraction=0.1, verbose=0, warm_start=False))]),\n",
       "       fit_params=None, iid='warn', n_jobs=-1,\n",
       "       param_grid={'lsi__svd__n_components': (100, 200, 300), 'lsi__vect__max_features': (500, 1000)},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=1)"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = {\n",
    "    'lsi__svd__n_components': (100,200, 300),\n",
    "    'lsi__vect__max_features': (500,1000),\n",
    "}\n",
    "\n",
    "grid_search_SGDClassifier = GridSearchCV(pipe_SGDClassifier,parameters, cv=5, n_jobs=-1, verbose=1)\n",
    "grid_search_SGDClassifier.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9264990328820116"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions on test sample\n",
    "prediction_SGDClassifier = grid_search.predict(test['description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# submission = pd.DataFrame({'id': test['id'], 'category':pred})\n",
    "# submission['category'] = submission['category'].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 3, 1, 1, 1, 1, 1, 1, 2, 1, 1, 4, 1, 1, 1, 1, 1, 1, 3, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 3, 1, 4, 2, 1, 1, 1, 1, 1, 3, 4, 1, 2, 1, 1, 1,\n",
       "       1, 1, 1, 2, 1, 1, 3, 1, 2, 1, 1, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 4,\n",
       "       2, 1, 1, 1, 1, 3, 1, 1, 4, 1, 3, 2, 1, 1, 4, 1, 2, 1, 1, 3, 2, 4,\n",
       "       1, 3, 1, 1, 1, 1, 1, 4, 1, 1, 4, 3, 1, 1, 1, 2, 1, 1, 1, 2, 1, 2,\n",
       "       3, 1, 1, 1, 1, 3, 1, 1, 1, 1, 3, 1, 2, 1, 1, 1, 1, 2, 2, 4, 1, 1,\n",
       "       1, 1, 3, 2, 1, 1, 1, 1, 1, 3, 2, 1, 1, 3, 4, 1, 1, 1, 3, 1, 1, 1,\n",
       "       1, 1, 3, 1, 1, 1, 1, 1, 4, 1, 1, 1, 3, 1, 2, 2, 1, 3, 3, 1, 1, 1,\n",
       "       1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1, 4, 1, 3, 1, 4, 1, 1, 2, 3, 1, 1,\n",
       "       2, 1, 1, 1, 1, 3, 2, 1, 1, 1, 1, 4, 1, 1, 3, 1, 2, 1, 1, 1, 1, 1,\n",
       "       1, 4, 2, 2, 2, 2, 1, 2, 2, 2, 1, 1, 1, 3, 1, 1, 2, 1, 1, 1, 1, 3,\n",
       "       2, 2, 1, 3, 1, 3, 3, 3, 1, 1, 2, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 3, 1, 3, 2, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 3, 4, 1, 1, 1, 3,\n",
       "       2, 1])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_SGDClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SGDC best option of it self!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect_SGDC = TfidfVectorizer(tokenizer=tokenize, ngram_range=(1,2), min_df=5, max_df=0.5)\n",
    "clf_SGDC = SGDClassifier(n_iter=300, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:152: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('vect', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.float64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=0.5, max_features=None, min_df=5,\n",
       "        ngram_range=(1, 2), norm='l2', preprocessor=None, smooth_idf=True,\n",
       "...m_state=None, shuffle=True, tol=None,\n",
       "       validation_fraction=0.1, verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_SGDC = Pipeline([\n",
    "                 ('vect', vect_SGDC), \n",
    "                 ('clf', clf_SGDC )\n",
    "                ])\n",
    "\n",
    "pipe_SGDC.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9517374517374517\n"
     ]
    }
   ],
   "source": [
    "prediction_SGDC = pipe_SGDC.predict(x_val)\n",
    "print(\"Accuracy:\", accuracy_score(y_val, prediction_SGDC))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This was the best !  LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = TfidfVectorizer(tokenizer=tokenize, ngram_range=(1,2), min_df=5, max_df=0.5)\n",
    "clf_LSVC = LinearSVC()\n",
    "\n",
    "'''\n",
    "Linear Support Vector Classification.\n",
    "Similar to SVC with parameter kernel=’linear’, but implemented in terms of liblinear rather than libsvm, so it has more flexibility in the choice of penalties and loss functions and should scale better to large numbers of samples.\n",
    "This class supports both dense and sparse input and the multiclass support is handled according to a one-vs-the-rest scheme.\n",
    "\n",
    "\n",
    "Between SVC and LinearSVC: SVC(kernel = 'linear') equivalent LinearSVC()\n",
    "LinearSVC tends to be faster to converge the larger the number of samples is.\n",
    "\n",
    "SVC https://towardsdatascience.com/https-medium-com-pupalerushikesh-svm-f4b42800e989\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('vect', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.float64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=0.5, max_features=None, min_df=5,\n",
       "        ngram_range=(1, 2), norm='l2', preprocessor=None, smooth_idf=True,\n",
       "...ax_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0))])"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the Pipeline\n",
    "pipe_LSVC = Pipeline([\n",
    "                 ('vect', vect), \n",
    "                 ('clf', clf_LSVC)\n",
    "                ])\n",
    "\n",
    "pipe_LSVC.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9517374517374517\n"
     ]
    }
   ],
   "source": [
    "prediction_LSVC = pipe_LSVC.predict(x_val)\n",
    "print(\"Accuracy:\", accuracy_score(y_val, prediction_LSVC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred_LSVC = pipe_LSVC.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({'id': test['id'], 'category': test_pred_LSVC})\n",
    "submission.to_csv('submission3.csv', index=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.calibration import CalibratedClassifierCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect_LSVC2 = TfidfVectorizer(tokenizer=tokenize)\n",
    "clf_LSVC2 = CalibratedClassifierCV(method='sigmoid',  #sigmoid will use Platt's scaling. Refer to documentation for other methods.\n",
    "                                        cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_LSVC2 = Pipeline([('vect', vect_LSVC2), ('clf', clf_LSVC2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('vect', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.float64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
       "...    vocabulary=None)), ('clf', CalibratedClassifierCV(base_estimator=None, cv=5, method='sigmoid'))])"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_LSVC2.fit(x_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9517374517374517\n"
     ]
    }
   ],
   "source": [
    "prediction_LSVC = pipe_LSVC.predict(x_val)\n",
    "print(\"Accuracy:\", accuracy_score(y_val, prediction_LSVC))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLP (Python3)",
   "language": "python",
   "name": "nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
